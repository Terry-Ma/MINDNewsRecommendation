preprocess:
  max_len: 1024
  min_freq: 5
  vocab_path: '../data/rnn.vocab'
  is_demo: 0

model:
  embed_size: 256
  hidden_size: 256
  attention_head_num: 8
  attention_size: 256

train:
  multi_gpu: 0
  batch_size: 128
  optimizer: 'Adam'   # Adam & SGD
  lr: 0.0003
  momentum: 0.0
  weight_decay: 0.0    # torch L2
  lr_scheduler: ''   # 'step' & 'metric' & ''
  lr_step_size: 2000
  lr_step_gamma: 0.8
  train_steps: 20000
  steps_per_check: 100
  steps_per_checkpoint: 5000
  checkpoint_path: 'RNN/'